{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file shows the complete process of developing the model from preprocessing to training and finding suitable parameters\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "First, read the csv file and drop unused columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function drops unused columns, calculates the mean of collinear variables and adds a new column \"month\" describing in which month the observation was measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def transform_data_median(data):\n",
    "    def mean_by_height(substring):\n",
    "        return data.filter(like = substring).filter(like = \".mean\").median(axis = 1)\n",
    "    \n",
    "    def std_by_height(substring):\n",
    "        return data.filter(like = substring).filter(like = \".std\").median(axis = 1)\n",
    "    \n",
    "    data = data.drop([\"id\", \"partlybad\"], axis = 1)\n",
    "    class2 = np.array([\"nonevent\", \"event\"])\n",
    "    data.insert(1, \"class2\", class2[(data[\"class4\"] != \"nonevent\").astype(int)])\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "    new_data[['date', 'class2']] = data[['date', 'class2']]\n",
    "    new_data[\"CO.mean\"] = mean_by_height(\"CO\")\n",
    "    new_data[\"CO.std\"] = std_by_height(\"CO\")\n",
    "    new_data[\"H2O.mean\"] = mean_by_height(\"H2O\")\n",
    "    new_data[\"H2O.std\"] = std_by_height(\"H2O\")\n",
    "    new_data[\"RHIRGA.mean\"] = mean_by_height(\"RHIRGA\")\n",
    "    new_data[\"RHIRGA.std\"] = std_by_height(\"RHIRGA\")\n",
    "    new_data[\"NOx.mean\"] = mean_by_height(\"NOx\")\n",
    "    new_data[\"NOx.std\"] = std_by_height(\"NOx\")\n",
    "    new_data[\"NET.mean\"] = mean_by_height(\"NET\")\n",
    "    new_data[\"NET.std\"] = std_by_height(\"NET\")\n",
    "    new_data[\"NO.mean\"] = data.iloc[:,27:39].filter(like = \".mean\").median(axis = 1)\n",
    "    new_data[\"NO.std\"] = data.iloc[:,27:39].filter(like = \".std\").median(axis = 1)\n",
    "    new_data[\"O3.mean\"] = data.iloc[:,51:61].filter(like = \".mean\").median(axis = 1)\n",
    "    new_data[\"O3.std\"] = data.iloc[:, 51:61].filter(like = \".std\").median(axis = 1)\n",
    "    new_data[['Pamb0.mean', 'Pamb0.std', 'PAR.mean', 'PAR.std', 'PTG.mean', 'PTG.std', 'RGlob.mean', 'RGlob.std']] = data[['Pamb0.mean', 'Pamb0.std', 'PAR.mean', 'PAR.std', 'PTG.mean', 'PTG.std', 'RGlob.mean', 'RGlob.std']]\n",
    "    new_data[['RPAR.mean', 'RPAR.std', 'SO2168.mean', 'SO2168.std', 'SWS.mean', 'SWS.std']] = data[['RPAR.mean', 'RPAR.std', 'SO2168.mean', 'SO2168.std', 'SWS.mean', 'SWS.std']]\n",
    "    new_data[\"T.mean\"] = data.filter(like = \"T\").iloc[:,4:].filter(like = \".mean\").median(axis = 1)\n",
    "    new_data[\"T.std\"] = data.filter(like = \"T\").iloc[:,4:].filter(like = \".std\").median(axis = 1)\n",
    "    new_data[['UV_A.mean', 'UV_A.std', 'UV_B.mean', 'UV_B.std', 'CS.mean', 'CS.std']] = data[['UV_A.mean', 'UV_A.std', 'UV_B.mean', 'UV_B.std', 'CS.mean', 'CS.std']]\n",
    "    new_data.set_index('date')\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification\n",
    "\n",
    "After preprocessing, we can start to develop the model. From previous testing, it was found that logistic regression is the best performer. But before that, we need to scale our data with standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "train_data = transform_data_median(pd.read_csv(\"npf_train.csv\"))\n",
    "test_data = transform_data_median(pd.read_csv(\"npf_test.csv\"))\n",
    "\n",
    "X_train = train_data.iloc[:,2:]\n",
    "y_train = (train_data.iloc[:,1] == 'event').astype(float)\n",
    "\n",
    "X_test = test_data.iloc[:,2:]\n",
    "y_test = (test_data.iloc[:,1] == 'event').astype(float)\n",
    "\n",
    "#Scale the data\n",
    "scaler = StandardScaler().fit(pd.concat([X_train, X_test], axis = 0))\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Feature selection\n",
    "lsvc = LinearSVC(C = 0.1, penalty = 'l1', dual = False).fit(X_train,y_train)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "\n",
    "#Apply the same model to the test data\n",
    "X_train = model.transform(X_train)\n",
    "X_test = model.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating accuracy for binary classification\n",
    "\n",
    "To avoid overfitting, we reduce the dimensions with PCA. We will choose number of components with k-fold cross-validation on logistic regression. L2 regularization is used to lower the variance to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated accuracy of the model is: 0.8792893875642823\n",
      "The estimated MSE is 0.12071061243571761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "clf = LogisticRegression(penalty = 'l1', C = 1/4, solver = \"saga\", max_iter = 5000)\n",
    "\n",
    "scores = cross_validate(\n",
    "    clf, X_train, y_train, cv = 5, scoring = ('accuracy', 'neg_mean_squared_error')\n",
    ")\n",
    "\n",
    "est_acc = scores['test_accuracy'].mean()\n",
    "mean_squared = -scores['test_neg_mean_squared_error'].mean()\n",
    "print(f'The estimated accuracy of the model is: {est_acc}')\n",
    "print(f'The estimated MSE is {mean_squared}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class4</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>event</td>\n",
       "      <td>0.892169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.104427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.024644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.072150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.026927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>event</td>\n",
       "      <td>0.646027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.014614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>event</td>\n",
       "      <td>0.912476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.004240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>event</td>\n",
       "      <td>0.885903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class4         p\n",
       "0       event  0.892169\n",
       "1    nonevent  0.104427\n",
       "2    nonevent  0.024644\n",
       "3    nonevent  0.072150\n",
       "4    nonevent  0.026927\n",
       "..        ...       ...\n",
       "960     event  0.646027\n",
       "961  nonevent  0.014614\n",
       "962     event  0.912476\n",
       "963  nonevent  0.004240\n",
       "964     event  0.885903\n",
       "\n",
       "[965 rows x 2 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame()\n",
    "\n",
    "predictions[\"class4\"] = clf.fit(X_train, y_train).predict(X_test)\n",
    "predictions[\"p\"] = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "predictions[\"class4\"] = predictions[\"class4\"].map({1.0: 'event', 0.0:'nonevent'})\n",
    "predictions.to_csv(\"answers.csv\", index = False)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8756476683937824"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class\n",
    "\n",
    "Only try to classify the event days since binary classifier already classifies nonevent days fairly accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.insert(1, \"class4\", pd.read_csv(\"npf_train.csv\")[\"class4\"])\n",
    "\n",
    "train_data_event = train_data[train_data[\"class4\"] != \"nonevent\"].drop(\"class2\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7396739130434782"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train_multiclass = X_train[(y_train == 1.0), :]\n",
    "y_train_multiclass, uniques = pd.factorize(train_data_event[\"class4\"])\n",
    "\n",
    "X_test_multiclass = X_test[np.array(predictions[\"class4\"] == \"event\"), :]\n",
    "y_test_multiclass = np.array(pd.read_csv(\"npf_test.csv\")[\"class4\"])[np.array(predictions[\"class4\"] == \"event\")]\n",
    "\n",
    "clf_randomForest = LogisticRegression(penalty = 'l1', C = 1/2, solver = \"saga\", max_iter = 5000, multi_class = 'multinomial')\n",
    "\n",
    "scores = cross_validate(\n",
    "    clf_randomForest, X_train_multiclass, y_train_multiclass, cv = 10, scoring = ('accuracy', 'neg_mean_squared_error')\n",
    ")\n",
    "\n",
    "random_forest_predictions = pd.DataFrame(clf_randomForest.fit(X_train_multiclass, y_train_multiclass).predict(X_test_multiclass), columns = [\"class4\"])\n",
    "random_forest_predictions = random_forest_predictions[\"class4\"].map({0: 'Ib', 1:'II', 2:'Ia'})\n",
    "random_forest_predictions.to_csv(\"multiclass_answers.csv\")\n",
    "\n",
    "scores[\"test_accuracy\"].mean()\n",
    "scores[\"test_neg_mean_squared_error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7088082901554404"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_predictions\n",
    "\n",
    "\n",
    "test_df = predictions[\"class4\"]\n",
    "\n",
    "#Combine the event day predictions to the binary predictions, and calculate the accuracy\n",
    "j = 0\n",
    "for i in range(test_df.shape[0]):\n",
    "    if (test_df[i] == \"event\"):\n",
    "        test_df.iloc[i] = random_forest_predictions.iloc[j]\n",
    "        j += 1\n",
    "\n",
    "test_df\n",
    "\n",
    "actual_class4 = pd.read_csv(\"npf_test.csv\")[\"class4\"]\n",
    "\n",
    "correct = (test_df == actual_class4)\n",
    "\n",
    "accuracy = correct.sum() / correct.size\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size = 0.5, random_state = 42\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
